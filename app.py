import streamlit as st
from groq import Groq
import pandas as pd

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Global Risk War-Room | Dynamic Engine",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# 2. Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (Secrets ë³´ì•ˆ ì ìš©)
try:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
except Exception:
    st.error("ğŸ”‘ Streamlit Secretsì— 'GROQ_API_KEY'ê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# ğŸ’¡ 3. ì„œë²„ì— ë¬¸ ë‘ë“œë¦¬ê¸°: ì‹¤ì‹œê°„ ê°€ìš© ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
@st.cache_data(ttl=3600) # 1ì‹œê°„ ë™ì•ˆ ìºì‹œ ìœ ì§€ (ì„œë²„ ë¶€í•˜ ë°©ì§€)
def fetch_available_models():
    try:
        models_data = client.models.list()
        # ìŒì„± ëª¨ë¸(whisper) ë° ë¯¸ë¦¬ë³´ê¸°ìš© ì¼ë¶€ ëª¨ë¸ ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ ëª¨ë¸ë§Œ í•„í„°ë§
        text_models = [
            m.id for m in models_data.data 
            if "whisper" not in m.id and "preview" not in m.id
        ]
        return text_models
    except Exception as e:
        st.sidebar.warning(f"ëª¨ë¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ìµœì†Œí•œì˜ ê¸°ë³¸ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (Fallback)
        return ["llama-3.3-70b-versatile", "llama-3.1-8b-instant", "mixtral-8x7b-32768"]

# ì‹¤ì‹œê°„ ëª¨ë¸ ëª©ë¡ ë¡œë“œ
available_models = fetch_available_models()

# 4. ì‚¬ì´ë“œë°”: ëª¨ë¸ ì—”ì§„ ì œì–´
with st.sidebar:
    st.title("ğŸ¤– Engine Settings")
    selected_model = st.selectbox(
        "Preferred AI Model (Live from Server)", 
        available_models,
        index=0
    )
    st.divider()
    st.info(f"í˜„ì¬ ì„œë²„ì—ì„œ {len(available_models)}ê°œì˜ í…ìŠ¤íŠ¸ ëª¨ë¸ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤.")
    st.caption("ì¥ì•  ë°œìƒ ì‹œ ë¦¬ìŠ¤íŠ¸ì˜ ë‹¤ìŒ ëª¨ë¸ë¡œ ìë™ ì „í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤.")

# 5. í•µì‹¬ ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜ (7ë‹¨ê³„ ê°€ì´ë“œ í”„ë ˆì„ì›Œí¬)
def generate_risk_report(incident_text, primary_model):
    system_prompt = """
    ë„ˆëŠ” ê¸€ë¡œë²Œ í”Œë«í¼ì˜ Senior Trust & Safety PMì´ì•¼. 
    ì…ë ¥ëœ ì‚¬ê±´ì— ëŒ€í•´ 'Operational Sensitivity'ë¥¼ ìœ ì§€í•˜ë©° ì•„ë˜ 7ë‹¨ê³„ í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´.
    ì–´íˆ¬ëŠ” ì°¨ê°‘ê³  ì „ë¬¸ì ì´ë©°, í‹±í†¡ ê°€ì´ë“œë¼ì¸ì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•´.
    
    1. Risk Level: Negligible, Low, Medium, High ì¤‘ íƒ 1
    2. Summary: ì‚¬ê±´ì˜ í•µì‹¬ (íŒ©íŠ¸ ì¤‘ì‹¬ 200ì)
    3. Platform Impact: í‹±í†¡ í”Œë«í¼ ì˜í–¥ ë° ì´ìœ  (100ì)
    4. Target Groups: íŠ¹ë³„ ë³´í˜¸ê°€ í•„ìš”í•œ ê³„ì¸µ (í•´ì‹œíƒœê·¸ í˜•íƒœ)
    5. Policy Mapping: ìœ„ë°˜ ì†Œì§€ê°€ í° ì»¤ë®¤ë‹ˆí‹° ê°€ì´ë“œë¼ì¸ ì¡°í•­
    6. Watchlist Keywords: ì£¼ì˜í•´ì•¼ í•  í‚¤ì›Œë“œ/ìŠ¬ëŸ¬/ì¸ë¬¼
    7. Action Plan: ìš´ì˜íŒ€ì„ ìœ„í•œ êµ¬ì²´ì  ëŒ€ì‘ ë°©ì•ˆ
    """

    # ê°€ìš©í•œ ì „ì²´ ëª¨ë¸ ì¤‘ ì„ íƒí•œ ëª¨ë¸ì„ 0ìˆœìœ„ë¡œ ë‘ê³  ìˆœì°¨ì  ì‹œë„ (ìœ ì—°í•œ êµ¬ì¡°)
    retry_queue = [primary_model] + [m for m in available_models if m != primary_model]
    
    for model in retry_queue:
        try:
            completion = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": incident_text}
                ],
                temperature=0.1 # ì‚¬ì‹¤ ê¸°ë°˜ ë¦¬í¬íŠ¸ë¥¼ ìœ„í•œ ë‚®ì€ ì°½ì˜ì„±
            )
            return completion.choices[0].message.content, model
        except Exception as e:
            st.sidebar.error(f"âš ï¸ {model} í˜¸ì¶œ ì‹¤íŒ¨, ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤...")
            continue
            
    return "ğŸš¨ ëª¨ë“  ê°€ìš© ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë‚˜ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.", None

# 6. ë©”ì¸ UI ë ˆì´ì•„ì›ƒ
st.title("ğŸ›¡ï¸ T&S Actionable Incident Guide")
st.markdown("---")

# ì…ë ¥ ì„¹ì…˜
incident_input = st.text_area(
    "ì‚¬ê±´ ê°œìš”ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
    placeholder="ì˜ˆ: ë¯¸ë‹ˆì• í´ë¦¬ìŠ¤ ICE ìš”ì› ì´ê²© ì‚¬ê±´ ë° ì‹¤ì‹œê°„ ë„ì‹±(Doxing) í™•ì‚° ì¤‘...",
    height=200
)

# ë¶„ì„ ì‹¤í–‰
if st.button("Generate Action Plan ğŸš€"):
    if not incident_input:
        st.warning("ë¶„ì„í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ì„œë²„ì™€ í†µì‹ í•˜ë©° ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            report, used_model = generate_risk_report(incident_input, selected_model)
            
            st.markdown(f"### ğŸ“Š Analysis Report (Source: {used_model})")
            st.divider()
            
            # ë¦¬í¬íŠ¸ ê²°ê³¼ ì¶œë ¥
            st.markdown(report)
            
            # ìœ í‹¸ë¦¬í‹° ê¸°ëŠ¥: í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            st.download_button(
                label="Download Analysis Report",
                data=report,
                file_name="incident_response_guide.txt",
                mime="text/plain"
            )

# í•˜ë‹¨ í‘¸í„°
st.divider()
st.caption("ğŸ”’ ë³¸ ë„êµ¬ëŠ” ë‚´ë¶€ Operational Sensitivity ê°•í™”ë¥¼ ìœ„í•œ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
